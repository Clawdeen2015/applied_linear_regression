<!DOCTYPE html>
<html>
  <head>
    <title>BANA 7052: Lecture 05</title>
    <meta charset="utf-8">
    <meta name="author" content="Brandon M. Greenwell" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# BANA 7052: Lecture 05
## Regression Models for Quantitative and Qualitative Predictors
### Brandon M. Greenwell
### 13 November, 2018

---

class: clear, middle, center



.font300[

[R code for these slides](https://github.com/bgreenwell/uc-bana7052/blob/master/code/lecture-05.R)

]


---
class: clear, middle

.font150[

* Required reading

    - Chapters: 3, 6, and 8

    - Sections: 3.9, 6.1, and 8.1-8.7

* Main topics:

    - Regression Models for Quantitative and Qualitative Predictors (8.1-8.7)
  
    - Transformations (3.9 and 6.1)

]


---

# Prerquisites

.scrollable[


```r
# List of required (CRAN) packages
pkgs &lt;- c(
  "ggplot2",  # for drawing nicer graphics
  "lattice",  # for drawing nicer graphics
  "MASS",     # for boxcox() function
  "tibble"    # for nicer data frames
)

# Install required (CRAN) packages
for (pkg in pkgs) {
  if (!(pkg %in% installed.packages()[, "Package"])) {
    install.packages(pkg)
  }
}
```

]


---
class: clear, center, middle

&lt;img src="lecture-05_files/figure-html/lets-go-1.svg" width="70%" style="display: block; margin: auto;" /&gt;


---

# Categorical predictors

.font115[

* Also called .magenta[*qualitative*] predictors or .magenta[*factors*]

    - [Free DataCamp exercise](https://campus.datacamp.com/courses/free-introduction-to-r/chapter-4-factors-4?ex=4)

]

--

.font115[

* [Wikipedia states that](https://en.wikipedia.org/wiki/Categorical_variable) "In statistics, a categorical variable is a variable that can take on one of a limited, and usually fixed number of possible values, assigning each individual or other unit of observation to a particular group or nominal category on the basis of some qualitative property."

    - Examples include gender (i.e., male/female), **zip code**, political affiliation, etc.

* In regression, we typically use .purple.bold[indicator variables] that take on the values 0 and 1 to identify the classes of a categorical variable

]


---

# Cutting tool example

.font120[

Suppose we want to relate the effective life of a cutting tool ( `\(Y\)` ) used on a lathe to the lathe speed in revolutions per minute ( `\(X_1\)` ) and type of cutting tool used ( `\(X_2\)` ).  

* Tool type is categorical variable and can be represented using an indicator variable of the form: `$$X_2 = \begin{cases} 0, &amp; \quad \text{if tool A} \\ 1, &amp; \quad \text{if tool B} \end{cases}$$`

* If a first-order model is appropriate, then `$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon$$`

]

--

.font150.center.purple.bold[This implies two separate models!]


---

# Cutting tool example

.font150[

`$$Y = \begin{cases} \beta_0 + \beta_1 X_1 + \epsilon, &amp; \quad \text{if tool A} \\ \left(\beta_0 + \beta_2\right) + \beta_1 X_1 + \epsilon, &amp; \quad \text{if tool B} \end{cases}$$`

]

--

&lt;img src="lecture-05_files/figure-html/cutting-tool-01-1.svg" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

&lt;img src="images/indicator-variables.png" width="100%" style="display: block; margin: auto;" /&gt;


---

# More than two categories

* In general, a categorical variable with `\(K\)` levels requires `\(K - 1\)` indicator variables

* For example, if there were three different tool types (i.e., A, B, and C), then the previous regression model would become: `$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon,$$` where `$$X_2 = \begin{cases} 1, &amp; \quad \text{if tool B} \\ 0, &amp; \quad \text{otherwise} \end{cases}$$` and `$$X_3 = \begin{cases} 1, &amp; \quad \text{if tool C} \\ 0, &amp; \quad \text{otherwise} \end{cases}$$`


---
class: clear, center, middle

&lt;img src="images/dummy-encoding.png" width="100%" style="display: block; margin: auto;" /&gt;


---

# Categorical variables in R

.code125[


```r
# Categorical variable
(dow &lt;- c("Mon", "Tue", "Wed", "Thu", "Fri"))
```

```
## [1] "Mon" "Tue" "Wed" "Thu" "Fri"
```

```r
class(dow)
```

```
## [1] "character"
```

]


---

# Categorical variables in R

.code125[


```r
# Coerce to a factor; needed for use in lm()
(dow2 &lt;- as.factor(dow))
```

```
## [1] Mon Tue Wed Thu Fri
## Levels: Fri Mon Thu Tue Wed
```

```r
class(dow2)
```

```
## [1] "factor"
```

]


---

# Categorical variables in R

.code110[


```r
# R will handle dummy encoding for you
model.matrix( ~ dow2)
```

```
##   (Intercept) dow2Mon dow2Thu dow2Tue dow2Wed
## 1           1       1       0       0       0
## 2           1       0       0       1       0
## 3           1       0       0       0       1
## 4           1       0       1       0       0
## 5           1       0       0       0       0
## attr(,"assign")
## [1] 0 1 1 1 1
## attr(,"contrasts")
## attr(,"contrasts")$dow2
## [1] "contr.treatment"
```

]


---

# Your turn

.font150[

The actual cutting tool data are available in [here](https://bgreenwell.github.io/uc-bana7052/data/cutting_tool.csv). Fit a linear regression model using `Hour` as the response and `rpm` (quantitative) and `ToolType` (qualitative with two categories) as the predictors of interest. Does the model fit seem reasonable? What do you conclude about the relationship between `Hour` and `rpm` for each category of `ToolType`?

]


---

# Solution

.font300[[R code](https://github.com/bgreenwell/uc-bana7052/blob/master/code/cutting-tool.R)]


---
class: clear, middle

.code125[


```r
# Load required packages
library(broom)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(lattice)

# Load the data
url &lt;- paste0("https://bgreenwell.github.io/",
              "uc-bana7052/data/cutting_tool.csv")
cutting_tool &lt;- read.csv(url)
```

]


---
class: clear, middle

.code125[


```r
# Inspect data
head(cutting_tool)
```

```
##    Hour rpm ToolType    Oil
## 1 18.73 610        A    Low
## 2 14.52 950        A    Low
## 3 17.43 720        A    Low
## 4 14.54 840        A    Low
## 5 13.44 980        A    Low
## 6 24.39 530        A Medium
```

]


---
class: clear, middle

.code125[


```r
# Check column types
sapply(cutting_tool, class)
```

```
##      Hour       rpm  ToolType       Oil 
## "numeric" "integer"  "factor"  "factor"
```

```r
# Inspect ToolType column
head(cutting_tool$ToolType)
```

```
## [1] A A A A A A
## Levels: A B
```

]


---
class: clear, middle

.code125[


```r
# How will R encode ToolType?
head(model.matrix( ~ rpm + ToolType, 
                   data = cutting_tool))
```

```
##   (Intercept) rpm ToolTypeB
## 1           1 610         0
## 2           1 950         0
## 3           1 720         0
## 4           1 840         0
## 5           1 980         0
## 6           1 530         0
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/cutting-tool-06-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle


```r
# Regression model
summary(fit &lt;- lm(Hour ~ rpm + ToolType, data = cutting_tool))
```

```
## 
## Call:
## lm(formula = Hour ~ rpm + ToolType, data = cutting_tool)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.5527 -1.7868 -0.0016  1.8395  4.9838 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 36.98560    3.51038  10.536 7.16e-09 ***
*## rpm         -0.02661    0.00452  -5.887 1.79e-05 ***
*## ToolTypeB   15.00425    1.35967  11.035 3.59e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.039 on 17 degrees of freedom
## Multiple R-squared:  0.9003,	Adjusted R-squared:  0.8886 
## F-statistic: 76.75 on 2 and 17 DF,  p-value: 3.086e-09
```


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/cutting-tool-08-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.font200[

Estimated regression equation:

]

.font170[

`$$\widehat{\text{Hour}} = \begin{cases} 36.986 - 0.027 \text{rpm}, &amp; \quad \text{tool A} \\ 51.990 - 0.027 \text{rpm}, &amp; \quad \text{tool B} \end{cases}$$`

]


---
class: clear, middle, center

&lt;img src="images/thinking-picard.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Unequal slopes

.font150.center.bold[

What if the slopes are expected to differ?

]

--

.font150[

Continuing with the previous cutting tool example:

* To model differing slopes, we can include an **interaction** (i.e., the product) between the qualitative and quantitative variables: `$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 + \epsilon$$`

]

--

.font150.center.bold.blue[What models are implied here?]


---

# Cutting tool example

.font150[

`$$Y = \begin{cases} \beta_0 + \beta_1 X_1 + \epsilon, &amp; \quad \text{if tool A} \\ \left(\beta_0 + \beta_2\right) + \left(\beta_1 + \beta_3\right) X_1 + \epsilon, &amp; \quad \text{if tool B} \end{cases}$$`

]

&lt;img src="lecture-05_files/figure-html/cutting-tool-unequal-slopes-1.svg" width="70%" style="display: block; margin: auto;" /&gt;


---

# Your turn

.font150[

Refit your previous regression model to the cutting tool data, but be sure to include an interaction between `rpm` and `ToolType`. **Hint:** use `:` to model an interaction between two predictors in `lm()` (i.e., `x1 + x2 + x1:x2`). Reinterpret your results. What are the two estimated prediction equations implied by this model? Use the general linear test approach to compare this model with the previous one. Which model do you conclude is "better"?

]


---

# Analysis of covariance (ANCOVA)

.font120[

* In many statistical studies, the goal is to compare two or more groups in terms of a continuous response `\(y\)` (e.g., the two-sample `\(t\)`-test or ANOVA)

* Oftentimes, however, additional information in the form of a continuous variable `\(x\)` may available to help in the comparison

    - Ideally, `\(x\)` will be correlated with `\(y\)`
    
* Our main interest lies in comparing the populations, but we would like to take into account the additional information contained in `\(x\)`

    - In this case, we call `\(x\)` a covariate

* We'll illustrate with an example

]


---

# Fruitfly example

.font125[

**It has been established that increased reproduction reduces longevity in female fruit flies. A study was conducted to see if the same effect exists for male fruit flies** (Hanley and Shapiro, 1994). The experiment consisted of five groups: males forced to (i) live alone, (ii) to live with one pregnant female, (iii) to live with eight pregnant females, (iv) to live with one fertile female, and (v) to live with eight fertile females. The response of interest is `lifespan` (measured in days). Variables also measured were `thorax` length (mm), and the percentage of each day spent sleeping. For our analysis, we will only focus on two groups: control group of males living with one pregnant female and an experiment group of males living with one fertile female; these are stored in the factor variable `group` with levels `"control"` and `"treatment"`. 

]


---

# Loading the data


```r
url &lt;- "https://bgreenwell.github.io/uc-bana7052/data/fruitfly.csv"
fruitfly &lt;- read.csv(url)
tibble::as_tibble(fruitfly)
```

```
## # A tibble: 50 x 3
##    lifespan group   thorax
##       &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt;
##  1       46 control   0.64
##  2       42 control   0.68
##  3       65 control   0.72
##  4       46 control   0.76
##  5       58 control   0.76
##  6       42 control   0.8 
##  7       48 control   0.8 
##  8       58 control   0.8 
##  9       50 control   0.82
## 10       80 control   0.82
## # ... with 40 more rows
```


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/fruitfly-02-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---

# A two-sample `\(t\)`-test

.scrollable[


```r
# Two-sample t-test
t.test(lifespan ~ group, data = fruitfly)
```

```
## 
## 	Welch Two Sample t-test
## 
## data:  lifespan by group
## t = 1.8585, df = 47.893, p-value = 0.06925
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.6585072 16.7385072
## sample estimates:
##   mean in group control mean in group treatment 
##                   64.80                   56.76
```

```r
# Linear model (equivalent)
summary(lm(lifespan ~ group, data = fruitfly))
```

```
## 
## Call:
## lm(formula = lifespan ~ group, data = fruitfly)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -35.76  -8.79   0.20  10.46  32.20 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      64.800      3.059  21.184   &lt;2e-16 ***
## grouptreatment   -8.040      4.326  -1.859   0.0692 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 15.29 on 48 degrees of freedom
## Multiple R-squared:  0.06713,	Adjusted R-squared:  0.0477 
## F-statistic: 3.454 on 1 and 48 DF,  p-value: 0.06923
```

]


---

# Full model

.scrollable[


```r
# Full model
fit1 &lt;- lm(lifespan ~ thorax + group + thorax * group, 
           data = fruitfly)

# Print model summary
summary(fit1)
```

```
## 
## Call:
## lm(formula = lifespan ~ thorax + group + thorax * group, data = fruitfly)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -25.9509  -9.2539   0.9361   7.3027  30.3071 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            -43.725     29.766  -1.469 0.148655    
## thorax                 131.450     35.931   3.658 0.000651 ***
## grouptreatment         -14.267     42.200  -0.338 0.736836    
## thorax:grouptreatment    5.551     50.575   0.110 0.913072    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 12.3 on 46 degrees of freedom
## Multiple R-squared:  0.4217,	Adjusted R-squared:  0.384 
## F-statistic: 11.18 on 3 and 46 DF,  p-value: 1.244e-05
```

]


---

# Reduced model

.scrollable[


```r
# Thorax only
fit2 &lt;- lm(lifespan ~ thorax, data = fruitfly)

# Print model summary
summary(fit2)
```

```
## 
## Call:
## lm(formula = lifespan ~ thorax, data = fruitfly)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -24.111  -8.825   1.207   7.707  35.143 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -45.82      22.22  -2.062   0.0447 *  
## thorax        128.18      26.63   4.813 1.52e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 13.01 on 48 degrees of freedom
## Multiple R-squared:  0.3255,	Adjusted R-squared:  0.3115 
## F-statistic: 23.17 on 1 and 48 DF,  p-value: 1.519e-05
```

```r
# Compare models
anova(fit2, fit1)
```

```
## Analysis of Variance Table
## 
## Model 1: lifespan ~ thorax
## Model 2: lifespan ~ thorax + group + thorax * group
##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1     48 8118.4                              
## 2     46 6961.1  2    1157.3 3.8239 0.02909 *
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]


---

# Testing for parallel slopes

.scrollable[


```r
# Parallel regression lines
fit3 &lt;- lm(lifespan ~ thorax + group, data = fruitfly)

# Print model summary
summary(fit3)
```

```
## 
## Call:
## lm(formula = lifespan ~ thorax + group, data = fruitfly)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.103  -9.123   1.092   7.273  30.267 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     -46.038     20.799  -2.214  0.03175 *  
## thorax          134.252     25.019   5.366 2.42e-06 ***
## grouptreatment   -9.651      3.456  -2.793  0.00753 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 12.17 on 47 degrees of freedom
## Multiple R-squared:  0.4215,	Adjusted R-squared:  0.3969 
## F-statistic: 17.12 on 2 and 47 DF,  p-value: 2.593e-06
```

```r
# Compare models
anova(fit3, fit1)
```

```
## Analysis of Variance Table
## 
## Model 1: lifespan ~ thorax + group
## Model 2: lifespan ~ thorax + group + thorax * group
##   Res.Df    RSS Df Sum of Sq     F Pr(&gt;F)
## 1     47 6962.9                          
## 2     46 6961.1  1    1.8233 0.012 0.9131
```

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/fruitfly-07-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font300[

Transformations

]


---

# Variance stabilizing transformations

.font125[

* Homoscedasticity is often violated when the variance is functionally related to the mean

    - If not satisfied, the estimated regression coefficients will have larger standard errors (i.e., less precision)

* Applying a transformation to the response may alleviate the problem

* The strength of the transformation depends on the amount of curvature that is induced

* While subject matter expertise and prior knowledge can be used to help select an appropriate transformation, such transformation are typically selected **empirically**

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/residuals-vs-x-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Useful transformations

.font150[

|  Relationship between `\(\sigma^2\)` and `\(E\left(Y\right)\)` | Transformation |
|:--|:--|
| `\(\sigma^2 \propto \text{constant}\)` | `\(Y^\star = Y\)` |
| `\(\sigma^2 \propto E\left(Y\right)\)` | `\(Y^\star = \sqrt{Y}\)` |
| `\(\sigma^2 \propto E\left(Y\right)\left[1 - E\left(Y\right)\right]\)` | `\(Y^\star = \sin^{-1}\left(\sqrt{Y}\right)\)` |
| `\(\sigma^2 \propto \left[E\left(Y\right)\right]^2\)` | `\(Y^\star = Y^{-1/2}\)` |
| `\(\sigma^2 \propto \left[E\left(Y\right)\right]^3\)` | `\(Y^\star = Y\)` |
| `\(\sigma^2 \propto \left[E\left(Y\right)\right]^4\)` | `\(Y^\star = Y^{-1}\)` |

]


---
class: clear, middle

.font125[

An electric utility is investigating the effect of the size of a single-family house and the type of air conditioning used in the house on the total electricity consumption during warm weather months

]

.code125[


```r
# Load the utility data
url &lt;- paste0("https://bgreenwell.github.io/",
              "uc-bana7052/data/utility.csv")
utility &lt;- read.csv(url)
head(utility, n = 5)  # print first 5 observations 
```

```
##   Customer Usage Demand
## 1        1   679   0.79
## 2        2   292   0.44
## 3        3  1012   0.56
## 4        4   493   0.79
## 5        5   582   2.70
```

]


---
class: clear, middle

.code125[


```r
# Scatterplot
plot(Demand ~ Usage, data = utility, pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5))

# Fitted regression line
abline(fit &lt;- lm(Demand ~ Usage, data = utility), 
       lwd = 2,
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/utility-03-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/utility-04-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle, center

.font300[

Which transformation(s) should we try? 

]

--

.font200[

(.red[This can involve a bit of trial and error!])

]


---
class: clear, middle

.code125[


```r
# Scatterplot
plot(sqrt(Demand) ~ Usage, data = utility, 
     pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5))

# Fitted regression line
*abline(fit &lt;- lm(sqrt(Demand) ~ Usage, data = utility),
       lwd = 2,
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/utility-06-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/utility-07-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Box-Cox procedure

.font150[

* Suppose that we wish to transform `\(Y\)` to correct for non-normality and/or non-constant variance (i.e., heteroscedasticity)

* A useful class of transformations is the power transformation, `\(Y^\lambda\)` where `\(\lambda\)` is a parameter to be estimated from the data

* The parameters of the regression model and `\(\lambda\)` can be estimated simultaneously using the method of maximum likelihood estimation

]


---

# Box-cox procedure

.font150[

* The Box-Cox transformation uses `$$Y_i^{\left(\lambda\right)} = \begin{cases} \frac{Y_i^\lambda - 1}{\lambda}, &amp; \quad \lambda \ne 0 \\ \ln\left(Y_i\right), &amp; \quad \lambda = 0 \end{cases}$$`

* The model to be fit is `$$Y_i^{\left(\lambda\right)} = \beta_0 + \beta_1 X_{i1} + \dots + \beta_{p-1} X_{i, p-1} + \epsilon_i \\ i = 1, 2, \dots, n$$`

* In R, you can use [MASS::boxcox()](https://www.rdocumentation.org/packages/MASS/versions/7.3-50/topics/boxcox) or [car::boxCox()](https://www.rdocumentation.org/packages/car/versions/2.1-4/topics/boxCox) to find the "optimal" value of `\(\lambda\)`

]



---
class: clear, middle

.code125[


```r
# Find optimal lambda value via ML estimation
bc &lt;- MASS::boxcox(Demand ~ Usage, data = utility)
```

&lt;img src="lecture-05_files/figure-html/boxcox-01-1.svg" width="60%" style="display: block; margin: auto;" /&gt;

```r
(lambda &lt;- bc$x[which.max(bc$y)])
```

```
## [1] 0.5454545
```

]


---
class: clear, middle


```r
# Scatterplot and fitted model
utility$Demand2 &lt;- (utility$Demand ^ lambda - 1) / lambda
plot(Demand2 ~ Usage, data = utility, pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5))
abline(fit &lt;- lm(Demand2 ~ Usage, data = utility), 
       lwd = 2,
       col = adjustcolor("darkred", alpha.f = 0.5))
```

&lt;img src="lecture-05_files/figure-html/boxcox-02-1.svg" width="80%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code125[


```r
par(mfrow = c(1, 2))  # side-by-side plots
plot(fit, which = 1:2)
```

&lt;img src="lecture-05_files/figure-html/boxcox-03-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]


---

# Transformations to linearize the model

.font150[

* Nonlinearity may be detected via plots or a *lack-of-fit* test 

* If a transformation of a nonlinear function can result in a linear function we say it is *intrinsically linear* or *transformably linear*

* Example: 

`$$Y = \beta_0\exp{\left(\beta_1 X\right)}\epsilon$$` 

]

--

.font150[

`$$\implies \ln{Y} = \ln{\beta_0} + \beta_1 X + \epsilon^\star \\ \implies Y^\star = \beta_0^\star + \beta_1 X + \epsilon^\star$$` 

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/prototype-01-1.svg" width="80%" style="display: block; margin: auto;" /&gt;

.font130[

Suggested transformations: `\(X^\star = \log_{10}\left(X\right)\)` or `\(X^\star = \sqrt{X}\)`

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/prototype-02-1.svg" width="80%" style="display: block; margin: auto;" /&gt;

.font130[

Suggested transformations: `\(X^\star = X^2\)` or `\(X^\star = \exp{\left(X\right)}\)`

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/prototype-03-1.svg" width="80%" style="display: block; margin: auto;" /&gt;

.font130[

Suggested transformations: `\(X^\star = 1/X\)` or `\(X^\star = \exp{\left(-X\right)}\)`

]


---

# Boston housing example 

.font150[

The data violate many classical assumptions like linearity, normality, and constant variance. Nonetheless, Harrison and Rubinfeld (1978) (using a combination of **transformations**, **significance testing**, and **grid searches**) were able to find a reasonable fitting model ( `\(R^2 = 0.81\)` ):

]

.font100[

`$$\widehat{\log\left(MV\right)} = 9.76 + 0.0063 RM^2 + 8.98\times10^{-5} AGE - 0.19\log\left(DIS\right) + 0.096\log\left(RAD\right) \\- 4.20\times10^{-4} TAX - 0.031 PTRATIO + 0.36\left(B - 0.63\right)^2 - 0.37\log\left(LSTAT\right) \\- 0.012 CRIM + 8.03\times10^{-5} ZN + 2.41\times10^{-4} INDUS + 0.088 CHAS \\- 0.0064 NOX^2$$`

]


---

# Windmill example

.font200[

A research engineer is investigating the use of a windmill to generate electricity and has collected data on the DC output from this windmill ( `\(X\)` ) and the corresponding wind velocity ( `\(Y\)` ).

]


---
class: clear, middle

.code125[


```r
# Load the windmill data
url &lt;- paste0("https://bgreenwell.github.io/",
              "uc-bana7052/data/windmill.csv")
windmill &lt;- read.csv(url)
head(windmill, n = 5)  # print first 5 observations 
```

```
##   Observation.Number Velocity Output
## 1                  1      5.0  1.582
## 2                  2      6.0  1.822
## 3                  3      3.4  1.057
## 4                  4      2.7  0.500
## 5                  5     10.0  2.236
```


]


---
class: clear, middle

.code115[


```r
# Scatterplot
plot(Output ~ Velocity, data = windmill, pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5),
     xlab = "Wind velocity", ylab = "DC output",
     main = "Original data")

# Fitted regression line
abline(fit &lt;- lm(Output ~ Velocity, data = windmill), 
       lwd = 2,
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/windmill-03-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code115[


```r
# Residual plot
plot(fitted(fit), rstudent(fit), pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5),
     xlab = "Fitted value", ylab = "Studentized residual",
     main = "Original data")
abline(h = 0, lty = 2, 
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/windmill-05-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code115[


```r
# Scatterplot
plot(Output ~ I(1/Velocity), data = windmill, pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5),
     xlab = "Wind velocity", ylab = "DC output",
     main = "Transformed data")

# Fitted regression line
abline(fit &lt;- lm(Output ~ I(1/Velocity), data = windmill), 
       lwd = 2,
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/windmill-07-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

.code115[


```r
# Residual plot
*plot(fitted(fit), rstudent(fit), pch = 19, las = 1,
     col = adjustcolor("darkblue", alpha.f = 0.5),
     xlab = "Fitted value", ylab = "Studentized residual",
     main = "Transformed data")
abline(h = 0, lty = 2, 
       col = adjustcolor("darkred", alpha.f = 0.5))
```

]


---
class: clear, middle

&lt;img src="lecture-05_files/figure-html/windmill-09-1.svg" width="100%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle 


```r
summary(fit)
```

```
## 
## Call:
## lm(formula = Output ~ I(1/Velocity), data = windmill)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.20547 -0.04940  0.01100  0.08352  0.12204 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     2.9789     0.0449   66.34   &lt;2e-16 ***
*## I(1/Velocity)  -6.9345     0.2064  -33.59   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.09417 on 23 degrees of freedom
## Multiple R-squared:   0.98,	Adjusted R-squared:  0.9792 
## F-statistic:  1128 on 1 and 23 DF,  p-value: &lt; 2.2e-16
```


---
class: clear, middle 

.center.font300[

⚠️⚠️⚠️

]

.font200[

The estimated coefficients still have the same properties, but only with respect to the transformed data, not the original data!

]

.center.font300[

⚠️⚠️⚠️

]


---

# Automated procedures

.font125[

* Alternating conditional expectations (ACE): uses the *alternating conditional expectations* algorithm to find the transformations of `\(Y\)` and `\(X\)` that maximize the proportion of variation in `\(Y\)` explained by `\(X\)`

* Additivity and variance stabilization for regression (AVAS): estimates transformations of `\(X\)` and `\(Y\)` such that the regression of `\(Y\)` on `\(X\)` is approximately linear with constant variance

    - Both of these procedures are available in the [acepack](https://cran.r-project.org/package=acepack) package for R
    
* Multivariate adaptive regression splines (MARS): piecewise linear splines approach to multiple linear regression that automatically models nonlinearities and interactions between variables

]


---
class: clear, middle, center

&lt;img src="lecture-05_files/figure-html/quittin-time-1.svg" width="60%" style="display: block; margin: auto;" /&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

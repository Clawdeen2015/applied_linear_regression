<!DOCTYPE html>
<html>
  <head>
    <title>Inferences in Simple Linear Regression</title>
    <meta charset="utf-8">
    <meta name="author" content="Brandon M. Greenwell" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Inferences in Simple Linear Regression
## Lecture 02
### Brandon M. Greenwell
### 23 September, 2018

---

class: clear 



background-image: url(images/research-walberg-normal-distribution.jpg)


---

# Reading assignment

.larger[

* Chapter: 2

    - Sections: TBD

* Main topics: TBD
  
]


---

# Prerquisites

.scrollable[


```r
# List of required (CRAN) packages
pkgs &lt;- c(
  "animation",  # for pre-built statistical animations
  "dplyr",      # for data wrangling
  "ggplot2",    # for awesome graphics
  "HistData",   # for historical data sets
  "tibble"      # for nicer data frames
)

# Install required (CRAN) packages
for (pkg in pkgs) {
  if (!requireNamespace(pkg)) {  # check if already installed first
    install.packages(pkg)  # install it
  }
}

# Install additional (optional) awesomeness
install.packages(c("devtools", "magick"))
devtools::install_github("bgreenwell/roundhouse")
```

]


---

# Ready to begin?

--


```r
roundhouse::kick("Chuck Norris counted to infinity, twice", 
                 width = 50)
```

&lt;img src="lecture-02_files/figure-html/roundhouse-01-1.gif" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear 

background-image: url(images/significance.png)
background-size: 40%


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-02-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
class: clear, middle

&lt;img src="lecture-02_files/figure-html/relationship-03-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---

# Inferences concerning `\(\beta_1\)`

.large[

* **Bad:** Is there a relationship between `\(X\)` and `\(Y\)`? (.red[not testable])

]

--

.large[

* **Good:** Is there a statistically significant linear relationship between `\(X\)` and `\(Y\)` at the `\(\alpha = 0.05\)` level? (.green[testable])

]

--

.large[

* How can we reformulate this as a statistical test?

]

--

.large[

$$
H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0
$$

]

--

.large[

* Need a point estimate, test statistic, reference distribution, etc.

]


---

# Properties of `\(\widehat{\beta}_1\)`

.huge[

What does the *bias* of a parameter estimate refer to? 🤔

]


---

# Properties of `\(\widehat{\beta}_1\)`

.large[

* Recall from the previous lecture that LS estimation provides the best linear unbiased estimates .blue[(BLUE)] of `\(\beta_0\)` and `\(\beta_1\)`; namely, `\(\widehat{\beta}_0\)` and `\(\widehat{\beta}_1\)`

    - Unbiased since `\(E\left[\widehat{\beta}_0\right] = \beta_0\)` and `\(E\left[\widehat{\beta}_1\right] = \beta_1\)`

    - Best in the sense that `\(\widehat{\beta}_0\)` and `\(\widehat{\beta}_1\)` have the smallest .purple[variance] among all other **linear unbiased** estimators of `\(\beta_0\)` and `\(\beta_1\)`, respectively

]

--

.large[

* So what is `\(Var\left[\widehat{\beta}_0\right]\)` and `\(Var\left[\widehat{\beta}_1\right]\)`?

]


---

# Properties of `\(\widehat{\beta}_1\)`

.large[

* Recall that the LS estimate of the slope is a weighted average of the (observed) response values: `\(\widehat{\beta}_1 = \sum_{i=1}^n w_iY_i\)` 

]

--

.large[

* Since the `\(Y_i\)` are independent, it follows that 

.small[

`$$Var\left(\widehat{\beta}_1\right) = Var\left(\sum_{i=1}^n w_iY_i\right) = \sum_{i=1}^n w_i^2Var\left(Y_i\right) = \dots = \sigma^2 / S_{xx}$$`

]

]


---

# Sampling distribution of `\(\widehat{\beta}_1\)`

.large[

* Assuming `\(\epsilon_i \stackrel{iid}{\sim} N\left(0, \sigma^2\right)\)`, then `\(\widehat{\beta}_1 \sim ???\)` 🤔

]

--
 
.large[

* `\(\widehat{\beta}_1 \sim N\left(\beta_1, \sigma^2/S_{xx}\right)\)`

]

--

.large[

* But we generally don't know `\(\sigma^2\)`, so how do we estimate it?

]

--

.large[

* Replace `\(\sigma^2\)` with its point estimate ($\widehat{\sigma}^2 = MSE$), and the sampling distribution of `\(\widehat{\beta}_1\)` becomes `\(\widehat{\beta}_1 \stackrel{\cdot}{\sim} N\left(\beta_1, \widehat{\sigma}^2/S_{xx}\right)\)`

]


---

# Standard errors

.large[

* .purple[The standard deviation of an estimate is referred to as its *standard error*]. For example,

`$$\sqrt{Var\left(\widehat{\beta}_1\right)} = SE\left(\widehat{\beta}_1\right) = \sigma/\sqrt{S_{xx}}$$`

]

--

.large[

* Since we don't know `\(\sigma^2\)`, we estimate `\(SE\left(\widehat{\beta}_1\right) = \sigma/\sqrt{S_{xx}}\)` with its *plug-in* estimate

`$$\widehat{SE}\left(\widehat{\beta}_1\right) = \widehat{\sigma}/\sqrt{S_{xx}}$$`

]


---

# Inference regarding `\(\beta_1\)`

* Hypothesis test: `\(H_0: \beta_1 = c \quad vs \quad H_1: \beta_1 \ne c\)`

--

* Test statistic: `$$t_{obs} = \frac{\widehat{\beta}_1 - c}{\widehat{SE}\left(\widehat{\beta}_1\right)} = \frac{\widehat{\beta}_1 - c}{\widehat{\sigma} / \sqrt{S_{xx}}}$$`

--

* Rejection `\(H_0\)` whenever `\(\left|t_{obs}\right| \ge t_{n - 2, 1 - \alpha/2}\)`

    - In R, `\(t\)` quantiles can be obtained using `qt(1 - alpha/2, df = n-2)`, for example
    

```r
alpha &lt;- 0.05           # significance level
n &lt;- 30                 # sample size         
*qt(1 - alpha/2, n - 2)  # cutoff value
```

```
## [1] 2.048407
```

--

* A `\(\left(1-\alpha\right)\)` 100% confidence interval for `\(\beta_1\)` is given by `\(\widehat{\beta}_1 \pm t_{n - 2, 1 - \alpha/2}\widehat{\sigma}/S_{xx}\)`


---

# Rocket propellant example

.scrollable[


```r
# Load the rocket propellant data
rocket &lt;- read.csv("https://bgreenwell.github.io/uc-bana7052/data/rocket.csv")

# Fit an SLR model
rocket_fit &lt;- lm(strength ~ age, data = rocket)

# Plot the data with the fitted mean response
investr::plotFit(rocket_fit)
```

&lt;img src="lecture-02_files/figure-html/rocket-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;

```r
# Print a summary of the fitted model
summary(rocket_fit)
```

```
## 
## Call:
## lm(formula = strength ~ age, data = rocket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.98  -50.68   28.74   66.61  106.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2627.822     44.184   59.48  &lt; 2e-16 ***
## age          -37.154      2.889  -12.86 1.64e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 96.11 on 18 degrees of freedom
## Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8964 
## F-statistic: 165.4 on 1 and 18 DF,  p-value: 1.643e-10
```

```r
# Compute a 95% CI for the slope
*confint(rocket_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) 2534.99540 2720.6493
## age          -43.22338  -31.0838
```

]


---
class: clear, middle

.large[

Can you interpret the confidence interval for `\(\beta_1\)` in the previous example?

]

--


```r
confint(rocket_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) 2534.99540 2720.6493
## age          -43.22338  -31.0838
```

With 95% confidence, we estimate that the mean strength of rockets decreases between 31.08 psi and 43.22 psi for every one-week increase in age.


---

# Your turn 😱

.huge[

Fit an SLR model to the crystal weight data using `weight` as the response and `time` as the predictor. Find a 95% confidence interval for the slope and interpret the results in **plain english**.

]


---

# Solution 🙌

.scrollable[


```r
# Load the crystal weight data
data(crystal, package = "investr")

# Fit an SLR model
crystal_fit &lt;- lm(weight ~ time, data = crystal)

# Plot the data with the fitted mean response
investr::plotFit(crystal_fit)
```

&lt;img src="lecture-02_files/figure-html/01-crystal-solution-01-1.png" width="70%" style="display: block; margin: auto;" /&gt;

```r
# Print a summary of the model
summary(crystal_fit)
```

```
## 
## Call:
## lm(formula = weight ~ time, data = crystal)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96371 -0.73464  0.05629  0.89193  1.40800 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.001429   0.599387   0.002    0.998    
## time        0.503429   0.035197  14.303 6.69e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.062 on 12 degrees of freedom
## Multiple R-squared:  0.9446,	Adjusted R-squared:   0.94 
## F-statistic: 204.6 on 1 and 12 DF,  p-value: 6.688e-09
```

```r
# Compute a 95% CI for the regression coefficients
*confint(crystal_fit, level = 0.95)
```

```
##                  2.5 %    97.5 %
## (Intercept) -1.3045241 1.3073812
## time         0.4267404 0.5801168
```

With 95% confidence, we estimate that the average weight of crystals increases between 0.43 grams and 0.58 grams for every one-hour increase in growth time.

]


---

# Rocket propellant example

.scrollable[

Using the rocket propellant example, test whether the slope significantly differs from `\(-40\)` psi/week at the `\(\alpha = 0.05\)` level.


```r
# Extract summary of estimated slope
*(slope &lt;- summary(rocket_fit)$coef["age", ])
```

```
##      Estimate    Std. Error       t value      Pr(&gt;|t|) 
## -3.715359e+01  2.889107e+00 -1.285989e+01  1.643344e-10
```

```r
# Compute test statistic
(t_obs &lt;- (slope["Estimate"] + 40) / slope["Std. Error"])  # &lt;&lt;
```

```
##  Estimate 
## 0.9852212
```

```r
# Compute cutoff from reference distribution
alpha &lt;- 0.05
n &lt;- nrow(rocket)
*(t_ref &lt;- qt(1 - alpha/2, df = n - 2))
```

```
## [1] 2.100922
```

```r
# Decision rule
if (abs(t_obs) &gt; t_ref) "reject H0" else "fail to reject H0"
```

```
## [1] "fail to reject H0"
```

]


---

# Your turn 😱

.large[

Using the crystal weight example, test whether the slope significantly differs from `\(3/4\)` grams/hour at the `\(\alpha = 0.1\)` level.

]


---

# Solution 🙌

.large[

`$$H_0: \beta_1 = 3/4 \quad vs \quad H_1: \beta_1 \ne 3/4$$`


```r
# Compute a 90% CI for the slope
confint(crystal_fit, parm = "time", level = 0.9)
```

```
##           5 %      95 %
## time 0.440697 0.5661602
```

Since 3/4 lies outside of the 90% confidence interval for `\(\beta_1\)`, we reject the null hypothesis at the 0.1 level and conclude that the slope significantly differs from 3/4. 

]


---

# Computing the *p*-value

.scrollable[

* One-sided test: `$$p = Pr\left(T_{n-2} &gt; \left|t_{obs}\right|\right)$$`

* Two-sided test: `$$p = 2 \times Pr\left(T_{n-2} &gt; \left|t_{obs}\right|\right)$$`


```r
*# From the rocket propellant example. What test does this correspond to?
*(t_obs &lt;- slope["Estimate"] / slope["Std. Error"])
```

```
##  Estimate 
## -12.85989
```

```r
*(p_val &lt;- 2 * pt(abs(t_obs), df = nrow(rocket) - 2, lower.tail = FALSE))
```

```
##     Estimate 
## 1.643344e-10
```

]


---

# Your turn 😱

.large[

Compute the *p*-value for the previous test in the crystal weight example. What is your decision?

]


---

# Solution 🙌

.medium[

`$$H_0: \beta_1 = 3/4 \quad vs \quad H_1: \beta_1 \ne 3/4$$`


```r
slope &lt;- summary(crystal_fit)$coef["time", ]
*(t_obs &lt;- (slope["Estimate"] - 3/4) / slope["Std. Error"])
```

```
##  Estimate 
## -7.005421
```

```r
*(p_val &lt;- 2 * pt(abs(t_obs), df = nrow(crystal) - 2, lower.tail = FALSE))
```

```
##     Estimate 
## 1.423506e-05
```

Since `\(p &lt; 0.1\)`, we reject the null hypothesis and conclude that the slope significantly differs from 3/4. 

]


---

# Inferences concerning `\(\beta_0\)`

* Similar results exist for the intercept, just replace `\(\widehat{SE}\left(\widehat{\beta}_1\right)\)` with `$$\widehat{SE}\left(\widehat{\beta}_0\right) = MSE\left(\frac{1}{n} + \frac{\bar{X}^2}{S_{xx}}\right)$$`


---
class: clear

.larger[

Consider the following hypotheses for the SLR model: `$$H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0$$`

]

--

.larger[

.center[

.red[

What does failing to reject `\(H_0\)` imply about the relationship between `\(X\)` and `\(Y\)`?

]

]

]


---

# ANOVA approach

.large[

* What does ANOVA refer to? 🤔

]

--

.large[

* Partitioning sums of squares (SS)

    - Total SS: `\(SST = SS_{tot} = \sum_{i=1}^n\left(Y_i - \bar{Y}\right)^2\)`
    
    - Error SS: `\(SSE = SS_{err} = \sum_{i=1}^n\left(Y_i - \widehat{Y}_i\right)^2\)`
    
    - Regression SS: `\(SSR = SS_{reg} = \sum_{i=1}^n\left(\widehat{Y}_i - \bar{Y}\right)^2\)`
    
]


---

# ANOVA approach

.large[

* `\(\left(Y_i - \bar{Y}\right) = \left(\widehat{Y}_i - \bar{Y}\right) + \left(Y_i - \widehat{Y}_i\right)\)`

]

-- 

.large[

* It is easy to show that the sums of these squared deviations have the same relationship: `$$\sum_{i=1}^n\left(Y_i - \bar{Y}\right) = \sum_{i=1}^n\left(\widehat{Y}_i - \bar{Y}\right) + \sum_{i=1}^n\left(Y_i - \widehat{Y}_i\right)$$`

    - In other words, `\(SST = SSS + SSE\)` (.purple[much like in a one-way ANOVA])

]


---

# ANOVA approach

.larger[

* Diving an SS by its associated *degrees of freedom* (df) produces mean squares (.purple[kind of like a standard deviation])

]

--

.larger[

* `\(MSR = \frac{SSR}{1}\)`

* `\(MSE = \frac{SSE}{1}\)`

]


---
class: clear, inverse, middle, center

.huge[

Is there a (linear) relationship between `\(X\)` and `\(Y\)`? `$$H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0$$`

]


---

# ANOVA approach

.large[

* Test statistic: `$$F_{obs} = \frac{MSR}{MSE}$$` with 1 .darkorange[numerator degrees of freedom] and `\(n-2\)` .darkorange[denominator degrees of freedom]

]

--

.large[

* Reject `\(H_0\)` at the `\(\alpha\)` level whenever `\(F_{obs} &gt; F_{1-\alpha, 1, n-2}\)`

    - Notice the use of `\(\alpha\)` as opposed to `\(\alpha/2\)` 🤔
    
    - Is a large value of `\(F_{obs}\)` good or bad?

]


---

# Rocket propellant example

.scrollable[


```r
# Compute ANOVA table for the fitted model
*anova(rocket_fit)
```

```
## Analysis of Variance Table
## 
## Response: strength
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## age        1 1527483 1527483  165.38 1.643e-10 ***
## Residuals 18  166255    9236                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
# Print summary of fitted model
summary(rocket_fit)
```

```
## 
## Call:
## lm(formula = strength ~ age, data = rocket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.98  -50.68   28.74   66.61  106.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2627.822     44.184   59.48  &lt; 2e-16 ***
## age          -37.154      2.889  -12.86 1.64e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 96.11 on 18 degrees of freedom
## Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8964 
## F-statistic: 165.4 on 1 and 18 DF,  p-value: 1.643e-10
```

]

---

# Your turn 😱

.larger[

Using the crystal weight example, use an *F*-test to test whether or not there is a relationship between `time` and `weight` at the `\(\alpha = 0.05\)` level. Manually compute the *p*-value for this test and 🙏 that it matches the output from `summary()`.

]


---

# Solution 🙌

.scrollable[


```r
# Print summary of the fitted model
summary(crystal_fit)
```

```
## 
## Call:
## lm(formula = weight ~ time, data = crystal)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96371 -0.73464  0.05629  0.89193  1.40800 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.001429   0.599387   0.002    0.998    
## time        0.503429   0.035197  14.303 6.69e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.062 on 12 degrees of freedom
## Multiple R-squared:  0.9446,	Adjusted R-squared:   0.94 
## F-statistic: 204.6 on 1 and 12 DF,  p-value: 6.688e-09
```

```r
# What values can we pull out from summary()
names(summary(crystal_fit))
```

```
##  [1] "call"          "terms"         "residuals"     "coefficients" 
##  [5] "aliased"       "sigma"         "df"            "r.squared"    
##  [9] "adj.r.squared" "fstatistic"    "cov.unscaled"
```

```r
# Observed test statitic
f_obs &lt;- summary(crystal_fit)$fstatistic

# Compute p-value (one approach)
pf(f_obs, df1 = 1, df2 = nrow(crystal) - 2, lower.tail = FALSE)
```

```
##        value        numdf        dendf 
## 6.687884e-09 3.370491e-01 4.681605e-03
```

```r
# Compute p-value (another approach)
1 - pf(f_obs, df1 = 1, df2 = nrow(crystal) - 2)
```

```
##        value        numdf        dendf 
## 6.687884e-09 3.370491e-01 4.681605e-03
```

]


---

# F or t?

.large[

* For every two-sided *t*-test, there is a corresponding *F*-test

    - `\(t_{obs}^2 = F_{obs}\)`

]

--

.large[

* In the SLR model, these the approaches are equivalent 

    - The *F*-test becomes useful when we start adding more predictors (i.e., in multiple linear regression)

]


---

# The general linear test

.large[

* Full model: `\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)`

]

--

.large[

* .magenta[Reduced] model: `\(Y_i = \beta_0 + \epsilon_i\)`

]

--

.large[

* Implied test: `\(H_0: \beta_1 = 0 \quad vs \quad H_1: \beta_1 \ne 0\)`

    - `\(F_{obs} = \frac{SSE(R) - SSE(F)}{df_R - df_F} \div \frac{SSE(F)}{df_F}\)`
    
    - Reject `\(H_0\)` whenever `\(F_{obs} &gt; F_{1 - \alpha, df_R - df_F, df_F}\)`
    
    - More useful in multiple linear regression, but we'll introduce it here!

]


---

# Rocket propellant example

.scrollable[


```r
# Fit an intercept only model
rocket_fit_reduced &lt;- lm(strength ~ 1, data = rocket)
*mean(rocket$strength)  # compare to estimated intercept
```

```
## [1] 2131.358
```

```r
*anova(rocket_fit_reduced, rocket_fit)  # compare models
```

```
## Analysis of Variance Table
## 
## Model 1: strength ~ 1
## Model 2: strength ~ age
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     19 1693738                                  
## 2     18  166255  1   1527483 165.38 1.643e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

]


---

# Rule of thumb 👍

.large[

Using 

`$$Esimtate \pm 2 \times SE$$`

for an approximate 95% CI is incredibly robust!


```r
*sapply(c(10, 20, 30, 50, Inf), function(x)
* qt(0.975, df = x))
```

```
## [1] 2.228139 2.085963 2.042272 2.008559 1.959964
```

]


---

# Estimation versus prediction

* Regression models are often used to predict a new response or estimate a mean
response for a given value of the predictor `\(X\)`

* We have seen how to compute a predicted value `\(\widehat{Y} = \widehat{\beta}_0 + \widehat{\beta}_1 X\)`

     - However, as with any estimate, we need a measure of reliability associated with `\(\widehat{Y}_0\)`.

* The fitted regression line for the 🚀 example is given by `$$\widehat{Y} = 2627.822 - 37.154 X$$` where `\(X\)` is the age in weeks of the rocket and `\(Y\)` is its psi strength

* Suppose we want to predict the strength of a new rocket at an age of 15 weeks. Then we would simply plug `\(X = 15\)` into the estimated regression equation to get a predicted value of `\(\widehat{Y} = 2627.822 − 37.154(15) = 2070.512\)` (psi).


---

# Estimation versus prediction 😕

* Regression analysis is really a problem of estimating a conditional mean or expectation, for example, in SLR we have `$$E\left(Y|X\right) = \beta_0 + \beta_1 X$$`

* Here, `\(E\left(Y|X\right)\)` corresponds to the average value of the response `\(Y\)` for all
units in the population with a specific `\(X\)` value

* Suppose we want to estimate the mean strength of .bold[all rockets] with an age of 15 weeks

    - For the prediction problem, we want to predict the strength of a **single rocket** at 15 weeks
    
    - For the estimation problem, we want to estimate the mean of the population of all rockets that are 15 weeks old 
    
    - In both cases, we use `\(\widehat{Y} = 2070.512\)` as the predicted strength and as the estimate of the mean strength of of rockets that are 15 weeks old

--

.center[.small[.content-box-yellow[

In other words, the point estimate is the same for prediction and estimation, the difference lies in the estimated standard error of each!

]


---

# Estimation versus prediction

* There is more uncertainty associated with prediction a single new observation (**Why?** 🤔)

* For a given value of `\(X\)`, it is customary to compute **confidence intervals for an estimated mean response** and a **prediction interval for a single new response value**

* The idea of a prediction interval is to determine an interval that will contain a certain percentage of the population

    - Because a prediction interval is attempting to capture a single, random future response, as opposed to the mean of the conditional population, it will be wider than the associated confidence interval

--

.center[.small[.content-box-yellow[

**My opinion:** confidence intervals for the mean response are far more common and useful in practice

]]]


---

# Anscombe's quartet

TBD


---

# CI for the mean response

.large[

* We can estimate the mean response given `\(X = X_0\)` as `\(\widehat{Y}_0 = \widehat{\beta}_0 + \widehat{\beta}_1 X_0\)` 

]

--

.large[

* How can we construct a CI for `\(\widehat{Y}\)`? 🤔

]

--

.large[

* What is the sampling distribution of `\(\widehat{Y}_0\)`? 🤔

]

--

.large[

For the normal error regression model `$$\frac{\widehat{Y}_0 - E\left(\widehat{Y}_0\right)}{\widehat{SE}\left(\widehat{Y}_0\right)} \sim t_{n-2}$$`

]


---

# CI for the mean response

.large[

* `\(E\left(\widehat{Y}_0\right) = \beta_0 + \beta_1 x_0\)`

* `\(\widehat{SE}\left(\widehat{Y}_0\right) = MSE\left[\frac{1}{n} + \frac{\left(X_0 - \bar{X}\right)^2}{S_{xx}}\right]\)`

]

--

.large[

A `\(1 - \alpha\)` CI for the mean response at `\(X = X_0\)` is given by `$$\widehat{Y}_0 \pm t_{1 - \alpha/2, n-2} MSE\left[\frac{1}{n} + \frac{\left(X_0 - \bar{X}\right)^2}{S_{xx}}\right]$$`

]

--

.medium[.center[.red[At what point is this interval smallest?]]]


---

# Rocket propellant example

Compute a 95% confidence interval for the mean response at 15 weeks

.scrollable[


```r
# Confidence interval for the mean response at age = 15
new_data &lt;- data.frame(age = 15)
predict(rocket_fit, newdata = new_data, interval = "confidence")
```

```
##        fit      lwr      upr
## 1 2070.518 2024.289 2116.748
```

```r
# Plot the (pointwise) confidence band around the fitted regression line
library(investr)  # for plotFit() function
plotFit(rocket_fit, interval = "confidence")
abline(v = 15, col = "red2")
```

&lt;img src="lecture-02_files/figure-html/rocket-06-1.png" width="70%" style="display: block; margin: auto;" /&gt;

```r
plotFit(rocket_fit, interval = "confidence", shade = TRUE, xlim = c(-20, 100))
```

&lt;img src="lecture-02_files/figure-html/rocket-06-2.png" width="70%" style="display: block; margin: auto;" /&gt;

]


---

# Your turn 😱

.larger[

Using the crystal weight example, compute a 90% confidence interval for the mean response at `\(X = 20\)` hours. Plot a (pointwise) 90% confidence band using the `investr::plotFit()` function. See `?predict.lm` and `?investr::plotFit` for help.

]


---

# Solution 🙌

.scrollable[


```r
# Confidence interval for the mean response at age = 15
new_data &lt;- data.frame(time = 20)
predict(crystal_fit, newdata = new_data, interval = "confidence",
*       level = 0.9)
```

```
##     fit      lwr      upr
## 1 10.07 9.474876 10.66512
```

```r
# Plot the (pointwise) confidence band around the fitted regression line
plotFit(crystal_fit, interval = "confidence", cex = 1.4, pch = 19, shade = TRUE,
        col.conf = adjustcolor("red2", alpha.f = 0.5))
```

&lt;img src="lecture-02_files/figure-html/01-crystal-solution-05-1.png" width="70%" style="display: block; margin: auto;" /&gt;

]


---
class: clear, middle, center


.larger[[Confidence intervals vs prediction intervals](https://stats.stackexchange.com/questions/16493/difference-between-confidence-intervals-and-prediction-intervals)]


---

# Coefficient of determination

.large[

* A useful performance metric in linear regression, called the *coefficient of determination*, is defined as `$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$`

]

--

.large[

* In linear regression, `\(R^2\)` can be interpreted as the fraction of variance explained (FVE) (i.e., the proportion of the variation in `\(Y\)` that can be explained by `\(X\)`)

    - `\(0 \le R^2 \le 1\)`

]


---

# Rocket propellant example

.scrollable[


```r
# Print model summary
summary(rocket_fit)
```

```
## 
## Call:
## lm(formula = strength ~ age, data = rocket)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.98  -50.68   28.74   66.61  106.76 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 2627.822     44.184   59.48  &lt; 2e-16 ***
## age          -37.154      2.889  -12.86 1.64e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 96.11 on 18 degrees of freedom
## Multiple R-squared:  0.9018,	Adjusted R-squared:  0.8964 
## F-statistic: 165.4 on 1 and 18 DF,  p-value: 1.643e-10
```

```r
# Extract R-squared from the model summary
summary(rocket_fit)$r.squared
```

```
## [1] 0.9018414
```

```r
# Compute R-squared by hand
anova(rocket_fit)
```

```
## Analysis of Variance Table
## 
## Response: strength
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## age        1 1527483 1527483  165.38 1.643e-10 ***
## Residuals 18  166255    9236                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
SSE &lt;- anova(rocket_fit)["Residuals", "Sum Sq"]
SST &lt;- sum((rocket$strength - mean(rocket$strength)) ^ 2)
1 - SSE/SST
```

```
## [1] 0.9018414
```

]


---

# Your turn 😢

.huge[

Compute the coefficient of determination (i.e., `\(R^2\)`) for the crystal weight example by hand .purple[and interpret its value].

]


---

# Solution 🙌

.scrollable[


```r
# Compute R-squared by hand
anova(crystal_fit)
```

```
## Analysis of Variance Table
## 
## Response: weight
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## time       1 230.631 230.631  204.58 6.688e-09 ***
## Residuals 12  13.528   1.127                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
SSE &lt;- anova(crystal_fit)["Residuals", "Sum Sq"]
SST &lt;- sum((crystal$weight - mean(crystal$weight)) ^ 2)
1 - SSE/SST
```

```
## [1] 0.9445927
```

Roughly 94.5% of the variability in the final weight of crystals is explained by the growth time. (At least in this sample.)

]


---

# Common misunderstandings about `\(R^2\)`

.large[

* A high `\(R^2\)` (i.e., near 1) indicates that a useful (i.e., accurate) prediction can be made

]

--

.large[

* A high `\(R^2\)` (i.e., near 1) indicates that the estimated regression line provides a good fit to the data

]

--

.large[

* A small `\(R^2\)` (i.e., near zero) indicates that `\(X\)` and `\(Y\)` are not related

]


---

# Other things to look out for 👀

.large[

* `\(R^2\)` will .red[always] increase when more terms are added to the model (.orange[more on this in multiple linear regression])

]

--

.large[

* As the range of `\(X\)` increases/decreases, `\(R^2\)` also generally increases/decreases

]

--

.large[

* `\(R^2\)` does not indicate the **appropriateness** of a linear model

]

--

.larger[.center[.blue[So why even use the coefficient of determination?]]]


---

# Coefficient of correlation

.larger[

In SLR, there is a connection between `\(R^2\)` and the Pearson correlation coefficient between `\(X\)` and `\(Y\)`: `$$r = \pm \sqrt{R^2}$$`

]

-- 

.large[.center[.blue[*r* will have the same sign as the estimated slope!]]]

---

# Rocket propellant example

.medium[


```r
# Compute coefficient of correlation
(r_squared &lt;- summary(rocket_fit)$r.squared)
```

```
## [1] 0.9018414
```

```r
sqrt(r_squared)
```

```
## [1] 0.9496533
```

```r
cor(rocket)  # compare with correlation coefficient
```

```
##            strength        age
## strength  1.0000000 -0.9496533
## age      -0.9496533  1.0000000
```

]


---

# Crystal weight example 🔮

.larger[

For the crystal weight data, rather than estimating the mean weight for crystals grown for 10 weeks, suppose we wanted to estimate how long we should grow the crystals such the average weight will be 10 grams. Use your intuition to derive a point estimate for this value. 

]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
